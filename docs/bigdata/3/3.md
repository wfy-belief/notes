# 3.3 HDFS 的 Shell 操作（一）

## 任务目的

- 掌握 Hadoop 集群管理脚本的使用方式
- 学会使用 `help` 命令查看指定命令的帮助信息
- 掌握操作 HDFS 文件或目录常用命令的使用方式

## 任务清单

- 任务 1：Hadoop 集群管理脚本
- 任务 2：HDFS 管理命令 fs
- 任务 3：操作 HDFS 文件或目录命令

## 详细任务步骤

### 任务 1：Hadoop 集群管理脚本

　　Shell 在计算机科学中俗称“壳”，是提供给使用者使用界面的进行与系统交互的软件，通过接收用户输入的命令执行相应的操作。

　　$HADOOP_HOME/bin 目录下的 **hadoop 脚本**是最基础的集群管理脚本，用户可以通过该脚本完成各种功能，如 HDFS 文件管理、MapReduce 作业管理等。我们可以键入 `hadoop` ，以查看更多的命令：

![Vditor](http://assets.qingjiaoclass.com/gdlzpoyzbkrj/20200514/bjveyovr_M9zIRXkNFKrBhdR3XG8c/1589427407ww/_image/1.png)

图1

　　从上图中得知，该脚本的使用方式：

```shell
hadoop [‐‐config confdir] COMMAND 
```

- --config：是用于设置 Hadoop 配置文件目录，默认目录为 $HADOOP_HOME/etc/hadoop/。
- COMMAND：是指具体的某个命令，常用的命令有：
  - fs：HDFS 管理命令
  - jar：作业提交命令
  - version：查看 Hadoop 版本

### 任务 2：HDFS 管理命令 fs

　　文件系统（FS）Shell 包含了各种的类 Shell 的命令，可以直接与 Hadoop 分布式文件系统以及其他文件系统进行交互，例如 Local FS 文件系统。

　　**在集群正常运行的前提下**，使用如下方法，进行 Shell 操作：

```shell
hadoop fs -help
```

　　展示的是 HDFS 支持的命令行参数：

![Vditor](http://assets.qingjiaoclass.com/gdlzpoyzbkrj/20200514/bjveyovr_M9zIRXkNFKrBhdR3XG8c/1589427407ww/_image/2.png)

图2

　　**注意：**

- 开始使用命令前，必须启动 Hadoop 集群。
- 以上指令均是在 Linux 命令行窗口界面操作。

- [ ]表示可选参数，<> 表示必须参数。

　　`help` 命令除了可以显示所有命令的帮助信息外，也可以用于显示指定命令的帮助信息，其语法格式如下：

```shell
hadoop fs -help [cmd ...]  
```

　　**示例：**

```shell
hadoop fs -help ls 
```

　　上述示例代码，执行完成后会展示指定命令 `ls` 的帮助信息。效果如下图所示：

![Vditor](http://assets.qingjiaoclass.com/gdlzpoyzbkrj/20200514/bjveyovr_M9zIRXkNFKrBhdR3XG8c/1589427407ww/_image/3.png)

图3

### 任务 3：操作 HDFS 文件或目录命令

　　上图显示了很多命令选项信息，可以看出，HDFS 支持的命令很多，本节我们讲解的是最常用的一部分，若需要了解全部命令或使用过程中遇到问题都可以使用`hadoop fs -help`命令获取帮助文档。

　　也可通过 Hadoop 官方文档 https://hadoop.apache.org/docs/r2.7.7/hadoop-project-dist/hadoop-common/FileSystemShell.html 学习。

#### 1. ls 命令

　　`ls` 命令**用于查看指定路径的当前目录结构**，类似于 Linux 系统中的 `ls` 命令，其语法格式如下：

```shell
hadoop fs -ls [-d] [-h] [-R] <path> 
```

　　其中，各项参数说明如下：

- -d：将目录显示为普通文件。
- -h：使用便于操作人员读取的单位信息格式。
- -R：递归显示所有子目录的信息。

　　**示例 1：**

```shell
hadoop fs -ls hdfs://localhost:9000/
hadoop fs -ls /	
```

　　上述示例代码，两条命令是等价的，执行完成后会**展示 HDFS 根目录下所有的文件和文件夹**。效果如下图所示：

![Vditor](http://assets.qingjiaoclass.com/gdlzpoyzbkrj/20200514/bjveyovr_M9zIRXkNFKrBhdR3XG8c/1589427407ww/_image/4.png)

图4

　　**示例 2：**

```shell
hadoop fs -ls -R -h /	
```

　　上述示例代码，执行完成后会**以更易读的单位信息格式递归展示**HDFS 根目录下所有的文件和文件夹，效果如下图所示：

![Vditor](http://assets.qingjiaoclass.com/gdlzpoyzbkrj/20200514/bjveyovr_M9zIRXkNFKrBhdR3XG8c/1589427407ww/_image/5.png)

图5

#### 2. mkdir 命令

　　`mkdir`命令**用于在指定路径下创建子目录**，其中创建的路径可以采用 URI 格式进行指定，与 Linux 命令 `mkdir` 相同，可以创建多级目录，其语法格式如下：

```shell
hadoop fs -mkdir [-p] <path> 
```

　　其中，`-p` 参数表示创建子目录来先检查路径是否存在，如果不存在，则创建相应的各级目录。

　　**示例：**

```shell
hadoop fs -mkdir -p /hadoop2.7.7/data
```

　　上述示例代码，是在 HDFS 的根目录下创建 hadoop2.7.7/data 层级文件夹，`-p` 参数表示递归创建路径中的各级目录。执行命令后效果如下图所示：

![Vditor](http://assets.qingjiaoclass.com/gdlzpoyzbkrj/20200514/bjveyovr_M9zIRXkNFKrBhdR3XG8c/1589427407ww/_image/6.png)

图6

#### 3. put 命令

　　`put` 命令等同于 `copyFromLocal`，**用于将本地系统的文件或文件夹复制到 HDFS 上**，其语法格式如下：

```shell
hadoop fs -put [-f] [-p] <localsrc> <dst>  
hadoop fs -copyFromLocal [-f] [-p] <localsrc> <dst> 
```

　　其中各项说明如下：

- -f：覆盖目标文件。
- -p：保留访问和修改时间、权限。

　　**示例：**

```shell
hadoop fs -put -f software/hadoop-2.7.7/README.txt /hadoop2.7.7/data
```

　　上述指令执行成功后，查询 HDFS 中 /hadoop2.7.7/data 目录，效果如下图所示：

![Vditor](http://assets.qingjiaoclass.com/gdlzpoyzbkrj/20200514/bjveyovr_M9zIRXkNFKrBhdR3XG8c/1589427407ww/_image/7.png)

图7

#### 4. get 命令

　　`get` 命令等同于 `copyToLocal`，**用于将 HDFS 的文件或文件夹复制到本地文件系统上**，其语法格式如下：

```shell
hadoop fs -get [-p] [-ignoreCrc] [-crc] <src> ... <localdst> 
hadoop fs -copyToLocal [-p] [-ignoreCrc] [-crc] <src> ... <localdst>
```

　　其中各项说明如下：

- -p：保留访问和修改时间、权限。
- -ignoreCrc：跳过对下载文件的 CRC 检查。
- -crc：为下载的文件写的 CRC 校验和，在本地文件系统生成一个。xxx.crc 的校验文件。

　　**示例：**

```shell
hadoop fs -get -crc /hadoop2.7.7/data/README.txt .
```

　　上述指令执行成功后，查询本地文件系统相应目录，效果如下图所示：

![Vditor](http://assets.qingjiaoclass.com/gdlzpoyzbkrj/20200514/bjveyovr_M9zIRXkNFKrBhdR3XG8c/1589427407ww/_image/8.png)

图8

#### 5. cp 命令

　　`cp` 命令用于**将指定文件从 HDFS 的一个路径（源路径）复制到 HDFS 的另外一个路径（目标路径）**。这个命令允许有多个源路径，此时目标路径必须是一个目录。其语法格式如下：

```shell
hadoop fs -cp [-f] [-p] <src> ... <dst>
```

　　其中各项说明如下：

- -f：覆盖目标文件。
- -p：保留访问和修改时间、权限。

　　**示例：**

```shell
hadoop fs -cp /hadoop2.7.7/data/README.txt /hadoop2.7.7
```

　　上述指令设置了一个源路径，效果如下图所示：

![Vditor](http://assets.qingjiaoclass.com/gdlzpoyzbkrj/20200514/bjveyovr_M9zIRXkNFKrBhdR3XG8c/1589427407ww/_image/9.png)

图9

#### 6. mv 命令

　　`mv` 命令**用于在 HDFS 目录中移动文件，不允许跨文件系统移动文件**。其语法格式如下：

```shell
hadoop fs -mv <src> ... <dst> 
```

　　**示例：**

```shell
hadoop fs -mv /hadoop2.7.7/README.txt /
```

　　上述指令将 /hadoop2.7.7 目录下的 README.txt 文件移动到了根目录下，效果如下图所示：

![Vditor](http://assets.qingjiaoclass.com/gdlzpoyzbkrj/20200514/bjveyovr_M9zIRXkNFKrBhdR3XG8c/1589427407ww/_image/10.png)

图10

#### 7. rm 命令

　　`rm` 命令**用于在 HDFS 中删除指定文件或文件夹。**默认情况下，HDFS 禁用了“回收站”功能，我们可以通过为参数“fs.trash.interval”（在 core-site.xml 中，单位为 min）设置大于零的值来启用“回收站”功能。其语法格式如下：

```shell
hadoop fs -rm [-f] [-r|-R] [-skipTrash] <src>
```

　　其中各项说明如下：

- -f：覆盖目标文件。
- -r|-R：递归删除目录。
- -skipTrash：绕过回收站（如果已启用），立即删除指定的文件或文件夹。

　　**示例：**

```shell
hadoop fs -rm /README.txt
hadoop fs -rm -r /hadoop2.7.7
```

　　执行上述指令，可以成功删除 HDFS 目录上的 README.txt 文件和 hadoop2.7.7 目录，效果如下图所示：

![Vditor](http://assets.qingjiaoclass.com/gdlzpoyzbkrj/20200514/bjveyovr_M9zIRXkNFKrBhdR3XG8c/1589427407ww/_image/11.png)

图11

#### 8. rmdir 命令

　　`rmdir` 命令**用于删除 HDFS 上的空目录。**其语法格式如下：

```shell
hadoop fs -rmdir  <dir>
```

　　**示例：**

```shell
hadoop fs -rmdir /test
```

　　上述指令只能删除空目录，若是删除非空目录，需要使用`rm -r`命令，效果如下图所示：

![Vditor](http://assets.qingjiaoclass.com/gdlzpoyzbkrj/20200514/bjveyovr_M9zIRXkNFKrBhdR3XG8c/1589427407ww/_image/12.png)