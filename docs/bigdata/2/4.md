# 2.4 Hadoop 集群初体验

## 任务目的

- 掌握启动 HDFS 集群和 YARN 集群的方式
- 进一步熟悉 HDFS 和 YARN 的 Web UI 界面
- 熟悉执行 MapReduce 程序的流程

## 任务清单

- 任务 1：启动 Hadoop 集群
- 任务 2：查看进程启动情况
- 任务 3：WordCount 单词统计案例
- 任务 4：PI 案例

## 详细任务步骤

### 任务 1：启动 Hadoop 集群

　　在本平台上，虽然已经为大家搭建好了 Hadoop 伪分布式集群，但是并没有启动，所以在使用集群之前，需要依次启动 **HDFS 集群**和 **YARN 集群**，这里我们使用**脚本一键启动**的方式启动。命令如下所示：

　　**（1）HDFS 集群**

　　在本机上使用如下方式一键启动 HDFS 集群：

```shell
start-dfs.sh
```

　　效果图如下所示：

![Vditor](http://assets.qingjiaoclass.com/gdlzpoyzbkrj/20200514/bjveyovr_Y2a0YmIRZfzDRlpMg63x/1589426391Zo/_image/1.png)

图1

　　**（2）YARN 集群**

　　在本机上使用如下方式一键启动 YARN 集群：

```shell
start-yarn.sh
```

　　效果图如下所示：

![Vditor](http://assets.qingjiaoclass.com/gdlzpoyzbkrj/20200514/bjveyovr_Y2a0YmIRZfzDRlpMg63x/1589426391Zo/_image/2.png)

图2

### 任务 2：查看进程启动情况

　　在本机上执行 `jps` 命令，在打印结果中会看到 6 个进程，分别是 NodeManager、SecondaryNameNode 、ResourceManager、Jps、DataNode 和 NameNode，如果出现了这 6 个进程表示进程启动成功。如下图所示：

![Vditor](http://assets.qingjiaoclass.com/gdlzpoyzbkrj/20200514/bjveyovr_Y2a0YmIRZfzDRlpMg63x/1589426391Zo/_image/3.png)

图3

### 任务 3：WordCount 单词统计案例

　　（1）首先，通过本机的浏览器访问 http://localhost:50070 或 [http://本机IP地址:50070](http://xn--ip-im8ckcs54ioc:50070/) 打开 HDFS 的 Web UI 界面。其次，选择 Utilities——》Browse the file system 查看文件系统里的数据文件，可以看到新建的 HDFS 上没有任何数据文件，如下图所示：

![Vditor](http://assets.qingjiaoclass.com/gdlzpoyzbkrj/20200514/bjveyovr_Y2a0YmIRZfzDRlpMg63x/1589426391Zo/_image/4.png)

图4

　　（2）在本机的/root 目录下，新建一个名为 data 的文件夹，然后再执行 “VIM word.txt” 指令新建一个 word.txt 文本文件，并编写一些单词内容，如下图所示：

![Vditor](http://assets.qingjiaoclass.com/gdlzpoyzbkrj/20200514/bjveyovr_Y2a0YmIRZfzDRlpMg63x/1589426391Zo/_image/5.png)

图5

　　（3）接着，在 HDFS 上创建 /wordcount/input 目录，并将 word.txt 文件上传至该目录下，具体指令如下所示：

```shell
 hadoop fs -mkdir -p /wordcount/input
 hadoop fs -put /root/data/word.txt /wordcount/input
```

　　效果如下所示：

![Vditor](http://assets.qingjiaoclass.com/gdlzpoyzbkrj/20200514/bjveyovr_Y2a0YmIRZfzDRlpMg63x/1589426391Zo/_image/6.png)

图6

　　上述指令是 Hadoop 提供的进行文件系统操作的 HDFS Shell 相关指令，此处不必深究具体使用，在下一章会进行详细说明。

　　执行完上述指令后，再次查看 HDFS 的 Web UI 界面，会发现 /wordcount/input 目录创建成功并上传了指定的 word.txt 文件，如下图所示：

![Vditor](http://assets.qingjiaoclass.com/gdlzpoyzbkrj/20200514/bjveyovr_Y2a0YmIRZfzDRlpMg63x/1589426391Zo/_image/7.png)

图7

　　（4）进入 $HADOOP_HOME/share/hadoop/mapreduce/ 目录下，使用`ll`指令查看文件夹内容，如下图所示：

![Vditor](http://assets.qingjiaoclass.com/gdlzpoyzbkrj/20200514/bjveyovr_Y2a0YmIRZfzDRlpMg63x/1589426391Zo/_image/8.png)

图8

　　从上图可以看出，在该文件夹下自带了很多 Hadoop 的 MapReduce 示例程序。其中，hadoop-mapreduce-examples-2.7.7.jar 包中包含了**计算单词个数**、**计算 PI 值**等功能的程序。

　　因此，这里可以直接使用 hadoop-mapreduce-examples-2.7.7.jar 示例包，对 HDFS 上的 word.txt 文件进行单词统计，在 jar 包位置执行如下命令：

```shell
hadoop jar hadoop-mapreduce-examples-2.7.7.jar wordcount /wordcount/input/word.txt /wordcount/output
```

　　上述指令中：

- hadoop jar hadoop-mapreduce-examples-2.7.7.jar ：表示执行一个 Hadoop 的 jar 包程序；
- wordcount：表示执行 jar 包程序中的单词统计功能；
- /wordcount/input/word.txt：表示进行单词统计的 HDFS 文件路径；
- /wordcount/output：表示进行单词统计后的输出 HDFS 结果路径。

　　执行完上述指令后，示例包中的 MapReduce 程序开始执行，效果图如下所示：

![Vditor](http://assets.qingjiaoclass.com/gdlzpoyzbkrj/20200514/bjveyovr_Y2a0YmIRZfzDRlpMg63x/1589426391Zo/_image/9.png)

图9

　　也可以通过 YARN 集群的 Web UI 界面查看运行状态，在本机的浏览器上访问 http://localhost:8088 或 [http://本机IP地址:8088](http://xn--ip-im8ckcs54ioc:8088/) 。效果图如下所示：

![Vditor](http://assets.qingjiaoclass.com/gdlzpoyzbkrj/20200514/bjveyovr_Y2a0YmIRZfzDRlpMg63x/1589426391Zo/_image/10.png)

图10

　　（5）在“单词统计”示例程序执行成功后，再次刷新并查看 HDFS 的 Web UI 界面，效果如下图所示：

![Vditor](http://assets.qingjiaoclass.com/gdlzpoyzbkrj/20200514/bjveyovr_Y2a0YmIRZfzDRlpMg63x/1589426391Zo/_image/11.png)

图11

　　从上图可以看出，MapReduce 程序执行成功后，在 HDFS 上自动创建了指定的输出目录 /wordcount/output，并且输出了 _SUCCESS 和 part-r-00000 结果文件。其中， _SUCCESS 文件用于表示此次任务成功执行的标识，而 part-r-00000 表示单词统计的结果。

　　（6）接着，我们使用 HDFS Shell 的相关指令查看 part-r-00000 的内容，具体指令如下所示：

```shell
hadoop fs -cat /wordcount/output/part-r-00000
```

　　效果如下图所示：

![Vditor](http://assets.qingjiaoclass.com/gdlzpoyzbkrj/20200514/bjveyovr_Y2a0YmIRZfzDRlpMg63x/1589426391Zo/_image/12.png)

图12

　　从上图可以看出，MapReduce 示例程序成功统计出了 /wordcount/input/word.txt 文本中的单词数量，并进行了结果输出。

### 任务 4：PI 案例

　　进入 $HADOOP_HOME/share/hadoop/mapreduce/ 目录下，使用如下指令计算 PI 值：

```shell
hadoop jar hadoop-mapreduce-examples-2.7.7.jar pi 5 5
```

　　上述指令中：

- hadoop jar hadoop-mapreduce-examples-2.7.7.jar ：表示执行一个 Hadoop 的 jar 包程序；
- pi：表示执行 jar 包程序中计算 PI 值的功能；
- 第 1 个 5：表示运行 10 次 map 任务；
- 第 2 个 5：表示每个 map 任务，投掷的次数。

　　执行完上述指令后，示例包中的 MapReduce 程序开始执行，效果图如下所示：

![Vditor](http://assets.qingjiaoclass.com/gdlzpoyzbkrj/20200514/bjveyovr_Y2a0YmIRZfzDRlpMg63x/1589426391Zo/_image/13.png)

图13

　　执行结果如下所示：

![Vditor](http://assets.qingjiaoclass.com/gdlzpoyzbkrj/20200514/bjveyovr_Y2a0YmIRZfzDRlpMg63x/1589426391Zo/_image/14.png)

图14

　　从上图可以看出，MapReduce 程序执行成功后，计算出了 PI 值。但是我们发现其计算结果与实际 PI 值有一定的偏差，若是想要计算更精切的 PI 值，我们可以将执行命令中的 2 个数值增大：

```shell
hadoop jar hadoop-mapreduce-examples-2.7.7.jar pi 100 10000
```

　　执行结果：

![Vditor](http://assets.qingjiaoclass.com/gdlzpoyzbkrj/20200514/bjveyovr_Y2a0YmIRZfzDRlpMg63x/1589426391Zo/_image/15.png)

图15

　　从结果可以验证，给出的数值越大，计算的 PI 值越精确，当然程序运行时间也会越长。若是想要提前结束程序，可以使用 `ctrl+c` 终止当前程序。