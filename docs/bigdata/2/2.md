# 2.2 HDFS 伪分布式集群搭建

## 任务目的

- 了解 Hadoop 集群的组成和规划
- 重点掌握 HDFS 集群的相关配置
- 掌握格式化文件系统的命令
- 学会启动和关闭 HDFS 集群的两种方式
- 能够使用 jps 命令查看进程的启动情况
- 能够通过 UI 查看 HDFS 集群的运行状态

## 任务清单

- 任务 1：Hadoop 集群简介
- 任务 2：安装包准备
- 任务 3：HDFS 集群主要配置文件讲解
- 任务 4：配置 Hadoop 系统环境变量
- 任务 5：HDFS 集群测试

## 任务步骤

### 任务 1：集群简介

　　Hadoop 集群具体来说包含两个集群：**HDFS 集群**和**YARN 集群**，两者逻辑上分离，但物理上常在一起。 另外，对于 Hadoop 的集群来讲，可以分为两大类角色：master 和 slave。

　　（1）**HDFS 集群**：负责海量数据的存储，集群中的角色主要有：**NameNode**（一个，master）、**DataNode**（若干，slave）和 **SecondaryNameNode**（一个）。
　　（2）**YARN 集群**：负责海量数据运算时的资源调度，集群中的角色主要有： **ResourceManager**（一个，master） 和 **NodeManager**（若干，slave）。

　　*为什么没有 MapReduce 集群呢？MapReduce 是什么呢？*
　　*它其实是一个应用程序开发包，也就是一堆 Java 的 jar 包，不需要安装。*

### 任务 2：安装包准备

　　Hadoop 是 Apache 基金会面向全球开源的产品之一，任何用户都可以从 Apache Hadoop 官网http://archive.apache.org/dist/hadoop/common/下载使用。本门课程将以当下较为稳定的 hadoop2.7.7 版本为例，详细讲解 Hadoop 的安装。所以我们下载 hadoop-2.7.7.tar.gz 即可。

　　现在已经为大家下载好了 hadoop2.7.7 的安装包，存放在 /root/software 目录下，使用如下命令进行解压即可使用：

```shell
tar -zxvf hadoop-2.7.7.tar.gz 
```

　　将其**解压到当前目录下**，即 /root/software 中，效果图如下所示：

![Vditor](http://assets.qingjiaoclass.com/gdlzpoyzbkrj/20200514/bjveyovr_4sUSXxY95AdBbDazxkOJ/1589426076BV/_image/22.jpg)

图1

　　接下来，进入 Hadoop 的安装目录，通过 `ll` 命令查看 Hadoop 目录结构，如下图所示：

![Vditor](http://assets.qingjiaoclass.com/gdlzpoyzbkrj/20200514/bjveyovr_4sUSXxY95AdBbDazxkOJ/1589426076BV/_image/23.jpg)

图2

　　从图中可以看出，Hadoop 安装目录包括 bin、etc、include、lib、libexec、sbin、share 共 7 个目录以及其他一些文件，下面简单介绍下各目录内容及作用。

　　（1）**bin**：存放操作 Hadoop 相关服务（HDFS、YARN）的脚本，但是通常使用 sbin 目录下的脚本。

　　（2）**etc**：存放 Hadoop 配置文件，主要包含 core-site.xml、hdfs-site.xml、mapred-site.xml 等从 Hadoop1.0 继承而来的配置文件和 yarn-site.xml 等 Hadoop2.0 新增的配置文件。

　　（3）**include**：对外提供的编程库头文件（具体动态库和静态库在 lib 目录中），这些头文件均是用 C++ 定义的，通常用于 C++ 程序访问 HDFS 或者编写 MapReduce 程序。

　　（4）**lib**：该目录包含了 Hadoop 对外提供的编程动态库和静态库，与 include 目录中的头文件结合使用。

　　（5）**libexec**：各个服务对应的 shell 配置文件所在的目录，可用于配置日志输出、启动参数（比如 JVM 参数）等基本信息。

　　（6）**sbin**：该目录存放 Hadoop 管理脚本，主要包含 HDFS 和 YARN 中各类服务的启动/关闭脚本。

　　（7）**share：Hadoop** 各个模块编译后的 jar 包所在的目录。

### 任务 3：HDFS 集群主要配置文件讲解

　　Hadoop 默认提供了两种配置文件：

　　（1）一种是**只读的默认配置文件**，包括 core-default.xml、hdfs-default.xml、mapred-default.xml 和 yarn-default.xml，这些文件包含了 Hadoop 系统各种默认配置参数；

　　（2）另一种是 **Hadoop 集群自定义配置时编辑的配置文件**（这些文件多数没有任何配置内容，都存在于 Hadoop 安装包下的 etc/hadoop 目录中），包括 hadoop-env.sh、yarn-env.sh、core-site.xml、hdfs-site.xml、mapred-site.xml、yarn-site.xml 和 slaves 共 7 个文件，可以根据需要在这些文件中对默认配置文件中的参数进行修改，Hadoop 会**优先**选择这些配置文件中的参数。

　　接下来，先通过下表对 Hadoop 集群搭建可能涉及的主要配置文件及功能进行描述。

| 配置文件        | 功能描述                                              |
| --------------- | ----------------------------------------------------- |
| hadoop-env.sh   | 配置 Hadoop 运行所需的环境变量                        |
| yarn-env.sh     | 配置 YARN 运行所需的环境变量                          |
| core-site.xml   | Hadoop 核心全局配置文件，可在其它配置文件中引用该文件 |
| hdfs-site.xml   | HDFS 配置文件，继承 core-site.xml 配置文件            |
| mapred-site.xml | MapReduce 配置文件，继承 core-site.xml 配置文件       |
| yarn-site.xml   | YARN 配置文件，继承 core-site.xml 配置文件            |
| slaves          | Hadoop 集群所有从节点（DataNode 和 NodeManager）列表  |

　　（1）前 2 个配置文件都是用来指定 Hadoop 和 YARN 所需运行环境。

- hadoop-env.sh：用来保证 Hadoop 系统能够正常执行 HDFS 的守护进程 NameNode、SecondaryNameNode 和 DataNode；
- yarn-env.sh：用来保证 YARN 的守护进程 ResourceManager 和 NodeManager 能正常执行。

　　（2）slaves 文件存储了当前集群的所有从节点的列表。

　　（3）其它 4 个配置文件都是用来设置集群运行参数的，在这些配置文件中可以使用 Hadoop 默认配置文件中的参数进行配置来优化 Hadoop 集群，从而使集群更加稳定高效。

　　Hadoop 提供的默认配置文件 core-default.xml、hdfs-default.xml、mapred-default.xml 和 yarn-default.xml 中的参数非常之多，这里不便一一展示说明。读者在具体使用时可以通过访问 Hadoop 官方文档https://hadoop.apache.org/docs/r2.7.7/，进入到文档最底部的 Configuration 部分进行学习和查看。

![Vditor](http://assets.qingjiaoclass.com/gdlzpoyzbkrj/20200514/bjveyovr_4sUSXxY95AdBbDazxkOJ/1589426076BV/_image/24.jpg)

图3

　　接下来，为大家详细讲解 HDFS 集群的相关配置，具体步骤如下。

#### 3.1 配置环境变量 hadoop-env.sh

　　因为 Hadoop 的**各守护进程依赖于 JAVA_HOME 环境变量**，所以需要修改“hadoop-env.sh”环境变量文件中的 JAVA_HOME 的值。

　　首先需要复制一下本机安装的 JDK 的实际位置（避免写错最好不要手写），可以使用下列方式打印 JDK 的安装目录：

```shell
echo $JAVA_HOME
```

　　语法解析：

- echo：输出命令
- $：引用环境变量的值
- JAVA_HOME：环境变量

　　效果图如下所示：

![Vditor](http://assets.qingjiaoclass.com/gdlzpoyzbkrj/20200514/bjveyovr_4sUSXxY95AdBbDazxkOJ/1589426076BV/_image/25.jpg)

图4

　　复制完成，使用如下命令打开 hadoop-env.sh 文件：

```shell
vim /root/software/hadoop-2.7.7/etc/hadoop/hadoop-env.sh 
```

　　找到 JAVA_HOME 参数位置，修改为本机安装的 JDK 的实际位置：

![Vditor](http://assets.qingjiaoclass.com/gdlzpoyzbkrj/20200514/bjveyovr_4sUSXxY95AdBbDazxkOJ/1589426076BV/_image/26.jpg)

图5

#### 3.2 配置核心组件 core-site.xml　　

　　该文件**是 Hadoop 的核心配置文件，其目的是配置 HDFS 地址、端口号，以及临时文件目录。**使用如下命令打开 “core-site.xml” 文件：

```shell
vim /root/software/hadoop-2.7.7/etc/hadoop/core-site.xml
```

　　将下面的配置内容添加到 `<configuration></configuration> `中间：

```xml
<!-- HDFS集群中NameNode的URI（包括协议、主机名称、端口号），默认为 file:/// --> 
<property> 
<name>fs.defaultFS</name> 
<!-- 用于指定NameNode的地址 -->
<value>hdfs://localhost:9000</value> 
</property> 
<!-- Hadoop运行时产生文件的临时存储目录 -->
<property> 
<name>hadoop.tmp.dir</name> 
<value>/root/hadoopData/temp</value> 
</property>
```

　　效果如下图所示：

![Vditor](http://assets.qingjiaoclass.com/gdlzpoyzbkrj/20200514/bjveyovr_4sUSXxY95AdBbDazxkOJ/1589426076BV/_image/28.jpg)

图6

#### 3.3 配置文件系统 hdfs-site.xml

　　该文件主要**用于配置 HDFS 相关的属性**，例如复制因子（即数据块的副本数）、NameNode 和 DataNode 用于存储数据的目录等。在完全分布式模式下，默认数据块副本是 **3 份**。 使用如下命令打开“hdfs-site.xml”文件：

```shell
vim /root/software/hadoop-2.7.7/etc/hadoop/hdfs-site.xml
```

　将下面的配置内容添加到 `<configuration></configuration> `中间：

```xml
<!-- NameNode在本地文件系统中持久存储命名空间和事务日志的路径 -->
<property> 
<name>dfs.namenode.name.dir</name> 
<value>/root/hadoopData/name</value>
</property> 
<!-- DataNode在本地文件系统中存放块的路径 -->
<property> 
<name>dfs.datanode.data.dir</name> 
<value>/root/hadoopData/data</value> 
</property> 
<!-- 数据块副本的数量，默认为3 -->
<property> 
<name>dfs.replication</name> 
<value>1</value> 
</property> 
```

　　效果如下图所示：

![Vditor](http://assets.qingjiaoclass.com/gdlzpoyzbkrj/20200514/bjveyovr_4sUSXxY95AdBbDazxkOJ/1589426076BV/_image/29.jpg)

图7

#### 3.4 配置 slaves 文件

　　该文件**用于记录 Hadoop 集群所有从节点（HDFS 的 DataNode 和 YARN 的 NodeManager 所在主机）的主机名**，用来配合**一键启动**脚本启动集群从节点（并且还需要保证关联节点配置了 SSH 免密登录）。

　　打开该配置文件：

```shell
vim /root/software/hadoop-2.7.7/etc/hadoop/slaves
```

　　我们看到其**默认内容为 localhost**，因为我们搭建的是伪分布式集群，就只有一台主机，所以从节点也需要放在此主机上，所以此配置文件无需修改。

### 任务 4：配置 Hadoop 系统环境变量

　　（1）首先打开/etc/profile 文件：

```shell
vim /etc/profile
```

　　（2）在文件底部添加如下内容：

```shell
# 配置Hadoop的安装目录		
export HADOOP_HOME=/root/software/hadoop-2.7.7	
# 在原PATH的基础上加入Hadoop的bin和sbin目录
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
```

　　注意：

- export 是把这两个变量导出为全局变量。
- 大小写必须严格区分。

　　另外：

- **bin：**存放操作 Hadoop 相关服务（HDFS、YARN）的脚本，但是通常使用 sbin 目录下的脚本。
- **sbin：**该目录存放 Hadoop 管理脚本，主要包含 HDFS 和 YARN 中各类服务的启动/关闭脚本。

　　如下图所示：

![Vditor](http://assets.qingjiaoclass.com/gdlzpoyzbkrj/20200514/bjveyovr_4sUSXxY95AdBbDazxkOJ/1589426076BV/_image/36.jpg)

图8

　　（3）让配置文件立即生效，使用如下命令：

```shell
source /etc/profile
```

　　（4）检测 Hadoop 环境变量是否设置成功，使用如下命令查看 Hadoop 版本：

```shell
hadoop version
```

　　执行此命令后，若是出现 Hadoop 版本信息说明配置成功：

![Vditor](http://assets.qingjiaoclass.com/gdlzpoyzbkrj/20200514/bjveyovr_4sUSXxY95AdBbDazxkOJ/1589426076BV/_image/37.jpg)

图9

### 任务 5：HDFS 集群测试

#### 5.1 格式化文件系统

　　具体指令如下：

```shell
hdfs namenode -format
```

　　执行格式化指令后，必须出现有“successfully formatted”信息才表示格式化成功，如下图所示：

![Vditor](http://assets.qingjiaoclass.com/gdlzpoyzbkrj/20200514/bjveyovr_4sUSXxY95AdBbDazxkOJ/1589426076BV/_image/38.jpg)

图10

　　若是未出现 “successfully formatted” 信息，就需要查看指令是否正确，或者之前 HDFS 集群的安装和配置是否正确，若是正确，则需要删除所有主机的 “/root/hadoopData” 文件夹，重新执行格式化命令，对 HDFS 集群进行格式化。

　　另外需要特别注意的是，上述格式化指令**只需要在 HDFS 集群初次启动前执行即可**，后续重复启动就不再需要执行格式化了。

#### 5.2 启动和关闭 HDFS 集群

　　针对 HDFS 集群的启动，启动方式有两种，一种是**单节点逐个启动**；另一种是**使用脚本一键启动**。

##### 1. 单节点逐个启动和关闭

　　单节点逐个启动的方式，需要参照以下方式逐个启动 HDFS 集群服务需要的相关服务进程，具体步骤如下：

　　（1）在本机上使用以下指令启动 NameNode 进程：

```shell
hadoop-daemon.sh start namenode
```

　　启动完成之后，使用 `jps` 指令查看 NameNode 进程的启动情况，效果如下图所示：

![Vditor](http://assets.qingjiaoclass.com/gdlzpoyzbkrj/20200514/bjveyovr_4sUSXxY95AdBbDazxkOJ/1589426076BV/_image/39.jpg)

图11

　　解析：

- jps 命令：（全称：Java Virtual Machine Process Status Tool）。安装 JDK 后在 % JAVA_HOME %/bin 目录下面自带的一个 Java 工具。能够显示系统当前运行的 Java 程序及其进程号。
- 其中 424 和 350 是进程的 PID，也就是进程号。

　　（2）在本机上使用以下指令启动 DataNode 进程：

```shell
hadoop-daemon.sh start datanode
```

　　（3）在本机上使用以下指令启动 SecondaryNameNode 进程：

```shell
hadoop-daemon.sh start secondarynamenode
```

　　另外，当需要停止相关服务进程时，只需要将上述指令中的`start`更改为`stop`即可。

##### 2. 脚本一键启动和关闭

　　**启动集群最常使用的方式是使用脚本一键启动**，前提是需要配置 SSH 免密登录。

- 在本机上使用如下方式一键启动 HDFS 集群：

```shell
start-dfs.sh
```

- 效果图如下所示：

![Vditor](http://assets.qingjiaoclass.com/gdlzpoyzbkrj/20200514/bjveyovr_4sUSXxY95AdBbDazxkOJ/1589426076BV/_image/40.jpg)

图12

　打印信息：

- 在本机上启动了 NameNode 守护进程

- 在本机上启动了 DataNode 守护进程

- 在配置的一个特定节点 0.0.0.0（本机）上启动 SecondaryNameNode 守护进程

  

　我们可以一键启动 HDFS 集群，同样也可以一键关闭 HDFS 集群，只需要将 `start` 改为 `stop` 即可，即`stop-dfs.sh`。

#### 5.3 查看进程启动情况

　　在本机执行 `jps `命令，在打印结果中会看到 4 个进程，分别是 NameNode、SecondaryNameNode、Jps、和 DataNode，如果出现了这 4 个进程表示进程启动成功。如下图所示：

![Vditor](http://assets.qingjiaoclass.com/gdlzpoyzbkrj/20200514/bjveyovr_4sUSXxY95AdBbDazxkOJ/1589426076BV/_image/42.jpg)

图13

#### 5.4 通过 UI 查看 HDFS 运行状态

　　HDFS 集群正常启动后，它默认开放了**50070**端口，**用于监控 HDFS 集群**。通过 UI 可以方便地进行集群的管理和查看，只需要在本地操作系统的浏览器输入**集群服务的 IP 和对应的端口号**即可访问。

　　通过本机的浏览器访问http://localhost:50070或http://本机IP 地址：50070 查看 HDFS 集群状态，效果如下图所示：

![Vditor](http://assets.qingjiaoclass.com/gdlzpoyzbkrj/20200514/bjveyovr_4sUSXxY95AdBbDazxkOJ/1589426076BV/_image/45.jpg)

图14

　　从上图可以看出，通过 UI 可以正常访问 Hadoop 集群的 HDFS 界面，并且页面显示正常，同时通过 UI 可以更方便地进行状态管理和查看。