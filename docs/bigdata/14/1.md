# 2.1 Hive 内嵌模式安装

<iframe 
src="https://player.bilibili.com/player.html?cid=207474396&aid=841237089&page=1&as_wide=1&high_quality=1&danmaku=0" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" width="640" height="430" > </iframe>

## 任务目的

- 了解 Hive 的三种运行模式
- 知道 Hive 的官方地址
- 掌握 Hive 内嵌模式的安装

## 任务清单

- 任务1：Hive 三种运行模式
- 任务2：Hive 安装地址
- 任务3：Hive 内嵌模式安装

## 任务步骤

### 任务1：Hive 三种运行模式

**1. 内嵌模式**

　　将元数据保存在本地内嵌的 **Derby 数据库**中，这是使用 Hive 最简单的方式。但是这种方式缺点也比较明显，因为一个内嵌的 Derby 数据库每次只能访问一个数据文件，这也就意味着它**不支持多会话连接**。

**2. 本地模式**

　　这种模式是将元数据保存在**本地独立的数据库**中（一般是 **MySQL**），这种方式是一个多用户的模式，运行多个用户 Client 连接到一个数据库中。这种方式一般**作为公司内部同时使用 Hive**。 这里有一个前提，每一个用户必须要有对 MySQL 的访问权利，即每一个客户端**使用者需要知道 MySQL 的用户名和密码**才行。

**3. 远程模式**

　　此模式应用于 **Hive 客户端较多**的情况。把 MySQL 数据库独立出来，**将元数据保存在远程独立的 MySQL 服务中**，避免了在每个客户端都安装 MySQL 服务从而造成冗余浪费的情况。此时**客户端无需知道 MySQL 的用户名和密码**。

### 任务2：Hive 安装地址

**1. Hive 官网地址**

http://hive.apache.org/

**2. 文档查看地址**

https://cwiki.apache.org/confluence/display/Hive/GettingStarted

**3. 下载地址**

http://archive.apache.org/dist/hive/

**4. github 地址**

https://github.com/apache/hive

### 任务3：Hive 内嵌模式安装

#### 3.1 Hive 安装

　　Hive是大数据生态圈中最常用的数据仓库，也是有 Hadoop 集群的公司的必备。所以 Hive 安装和使用也是大数据开发或运维人员都必须掌握的。Hive的安装很简单，而且 Hive1.0 和 Hive2.0 版本的安装非常类似，完全可以套用。**本门课程选择 hive2.3.4 作为教学版本！**

**1. 解压安装包**

　　现在已经为大家下载好了 hive2.3.4 的安装包，存放在 /root/software 目录下，首先进入此目录下，使用如下命令进行解压即可使用：

```shell
tar -zxvf apache-hive-2.3.4-bin.tar.gz
```

　　将其**解压到当前目录下**，即 /root/software 中，效果图如下所示：

![Vditor](https://cdn.jsdelivr.net/gh/wfy-belief/PicGo-images/img/63021091.jpg)

图1

**2. 配置环境变量**

　　（1）首先打开 /etc/profile 文件：

```shell
vim /etc/profile
```

　　（2）将以下内容添加到配置文件的底部，添加完成输入“:wq”保存退出：

```shell
# 配置Hive的安装目录		
export HIVE_HOME=/root/software/apache-hive-2.3.4-bin
# 在原PATH的基础上加入Hive的bin目录
export PATH=$PATH:$HIVE_HOME/bin
```

**注意：**

- export 是把这两个变量导出为全局变量。
- 大小写必须严格区分。

　　（3）让配置文件立即生效，使用如下命令：

```shell
source /etc/profile
```

　　（4）检测 Hive 环境变量是否设置成功，使用如下命令查看 Hive 版本：

```shell
hive --version
```

　　执行此命令后，若是出现 Hive 版本信息说明配置成功：

![Vditor](https://cdn.jsdelivr.net/gh/wfy-belief/PicGo-images/img/63021092.jpg)

图2

#### 3.2 内嵌模式安装

**1. 修改配置文件 hive-env.sh**

　　切换到 ${HIVE_HOME}/conf 目录下，将 hive-env.sh.template 文件**复制一份并重命名**为 hive-env.sh：

```shell
cp hive-env.sh.template hive-env.sh
```

　　修改完成，使用 **vi 编辑器**进行编辑：

```shell
vim hive-env.sh
```

　　在文件中配置 **HADOOP_HOME**、**HIVE_CONF_DIR** 以及**HIVE_AUX_JARS_PATH** 参数：

```shell
# 配置Hadoop安装路径
HADOOP_HOME=/root/software/hadoop-2.7.7

# 配置Hive配置文件存放路径
export HIVE_CONF_DIR=/root/software/apache-hive-2.3.4-bin/conf

# 配置Hive运行资源库路径
export HIVE_AUX_JARS_PATH=/root/software/apache-hive-2.3.4-bin/lib
```

　　如下图所示：

![Vditor](https://cdn.jsdelivr.net/gh/wfy-belief/PicGo-images/img/63021093.jpg)

图3

　　配置完成，输入“:wq”保存退出。

**2. 初始化元数据库**

　　注意：当使用的 Hive 是 2.x 之前的版本时，不做初始化也是 OK 的。Hive 第一次启动时会自动进行初始化，只不过不会生成足够多的元数据库的表，其它的在使用过程中会慢慢生成。**如果使用的是 2.x 版本的 Hive，那么就必须手动初始化元数据库。**使用如下命令进行初始化，这里我们使用 **Hive 默认的 db 类型 “derby”**：

```shell
schematool -dbType derby -initSchema
```

　　若是出现“schemaTool completed”则初始化成功，如下图所示：

![Vditor](https://cdn.jsdelivr.net/gh/wfy-belief/PicGo-images/img/63021094.jpg)

图4

　　初始化完成，会在当前目录下生成一个 **derby.log 文件**和一个 **metastore_db 目录**：

![Vditor](https://cdn.jsdelivr.net/gh/wfy-belief/PicGo-images/img/63021095.jpg)

图5

**3. Hive 连接**

　　在此目录下使用 Hive 的三种连接方式之一：**CLI 启动 Hive**。由于已经在环境变量中配置了 HIVE_HOME ，所以这里直接在命令行执行如下命令即可：

```shell
hive
或者
hive --service cli
```

　　效果如下图所示：

![Vditor](https://cdn.jsdelivr.net/gh/wfy-belief/PicGo-images/img/63021096.jpg)

图6

　　这种存储方式的弊端是**在同一个目录下同时只能有一个 Hive 客户端能使用数据库**，否则会提示 Hive 元数据有问题（这是一个很常见的错误）:

![Vditor](https://cdn.jsdelivr.net/gh/wfy-belief/PicGo-images/img/63021097.jpg)

图7

　　另外，要是想要在其它目录下操作 Hive，必须要在其它目录下重新初始化元数据库。